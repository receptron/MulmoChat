# The Dawn of the AI-Native Operating System

ChatGPTがOpenAIから発表されて3年が経とうとしています。その後、Function Call、MCP、Code Interpreter、Artifact、Multi-modal LLM、Agentなど、数多くの仕組みが生まれました。しかし、ChatGPTの基本的なインターフェイスはいまだに「テキストベースのチャット」に留まっています。

私たちソフトウェア・エンジニアの間で、Claude Codeのようなチャット形式のプログラミング環境が広く使われている事実は、LLMと人間の間の**自然言語インターフェイス（Natural Language Interface）**が、既存のGUIを超えるポテンシャルを持つことを示しています。

一方、MicrosoftのCoPilotのように、従来のアプリケーション（Excelなど）に自然言語インターフェイスを後付けする試みは、必ずしも成功していません。それは、これらのアプリケーションが「LLMが存在しない時代の設計思想」に基づいているからです。

同じ理由で、LLMにブラウザや既存アプリを操作させるアプローチにも限界があります。真にAIネイティブなアプローチとは、アプリケーションの機能をAPIとしてLLMに提示し、ユーザーの意図（Intent）を一連のAPIコールに変換することです。LLMが、ユーザーとアプリケーションの間のインタープリタの役割を果たすのです。

つまり、自然言語を理解するLLMの存在を前提としたAI-NativeなコンピュータのUser Experienceは、ユーザーとLLMの間のNLUIと、ユーザーとアプリケーションの間のGUIを融合したユーザー体験を提供すべきであり、アプリケーションのアーキテクチャそのものも従来とは大きく異なるものである必要があるのです。

本稿では、「AI-Nativeなコンピュータ（OS）のUser Experienceとアプリケーション・アーキテクチャ」という視点から、業界全体が向かうべき方向性を示すために設計された**MulmoChat（Multi-modal Chat）**というオープンソースのプロトタイプを紹介します。

## NLUIとGUIの融合

Function CallとMCP（以後はTool、もしくはTool Callと呼びます）は、LLMに外部機能を提供する仕組みとして登場しました。これらは、JSON形式のパラメータを受け取り、JSON形式の結果を返すという、テキストベースのインターフェイスです。

Tool Callの結果として、アプリケーション独自のウィンドウを表示したり、ブラウザーで特定のページを開くことは可能ですが、それらはチャットインターフェイスとは切り離されており、「NLUI（Natural Language UI）とGUIの融合」とは呼べません。

この問題を解決するために、MulmoChatではTool Callの仕組みを拡張し、NLUIとGUIの自然な統合を実現しました。具体的には、Tool Callのreturn valueを拡張し、LLMへの返答に加えて、ユーザーに表示すべきTool-specificなデータを返すことを可能にしています。このデータの表示は、システムに登録されたTool専用のビューアーが担当します。

このアーキテクチャにより、アプリケーションはチャット（NLUI）の流れの中で、独自のインタラクティブなGUIをリアルタイムに生成・操作できるようになります。

以下は、Excelに相当する表計算アプリケーションを、このアーキテクチャ上で動作させた場合の一例です。


1. 「SpreadSheet」アプリケーションは、LLMが呼び出せるtoolと、tool-specificなデータを表示するビューアーを登録する。
2. ユーザーが「Shows me the present value of $1000 monthly income over a year, making it easy to change the discount rate.」と指示を与える。
3. LLMはユーザーの意図（intent）を解釈し、"SpreadSheet" toolを呼び出すためのJSONデータを構築する。
4. Toolは、LLMに対して「表計算データを生成・表示中である」と通知し、システムに対しては生成したスプレッドシートデータを返す。
5. システムは返されたデータタイプを判定し、対応するビューアーを起動する。
6. ビューアーが生成されたスプレッドシートをユーザーに表示する。
7. ユーザーはGUI上で直接操作を行い、その結果が再びチャットコンテキスト（NLUI）にフィードバックされる。

このように、MulmoChatでは、LLM・GUI・ユーザーの三者が同一の文脈で連続的にやりとりできます。これこそが、NLUIとGUIの真の融合であり、AI-Nativeなコンピューティング環境における新しいユーザー体験の核となります。

![](https://mag2.thelifeisbeautiful.com/Nov2025/discount2.png)

## No more "See of Application Icons"

上のシナリオは、「ユーザー体験」という観点から、既存のシステムと大きく異なります。

多くのiPhoneユーザーは、数十から百個を超えるアプリケーションをインストールしています。そのため、何かをするたびに「無数のアプリ・アイコンの海の中から、必要なものを探し出す」という煩雑な作業を繰り返さなければなりません。
AI-Nativeなシステムでは、どのToolを使うかの判断はLLMが行います。

ユーザーは「アプリを選んで起動する」という作業から完全に解放されるのです。

表計算やプレゼン資料、文書作成などは、LLMが利用できるToolとしてシステムに登録されているだけで、ユーザーは「アプリケーション」という概念そのものから自由になります。

さらに、スプレッドシートやプレゼン資料のドラフトは、LLMが自動的に生成してくれるため、Learning Curve（学習コスト）は桁違いに低くなります。

下の図は、MulmoChatに対してユーザーが“Make a travel guide for Tokyo with pictures of 3 famous landmarks.”と指示した際の出力例です。Wordに相当するToolが呼び出され、わずか数十秒でドキュメントが生成されています。

![](https://mag2.thelifeisbeautiful.com/Nov2025/tokyo_guide.png)

ユーザーはこのドキュメントを起点に、情報を追記したり、LLMにさらなる指示を出して内容を更新できます。これにより、チャットがそのままドキュメント生成プロセスになるのです。

この仕組みは、ClaudeのArtifactやChatGPTのCanvasに似ていますが、二つの点で大きく異なります。

1. Extensibility（拡張性）

　ArtifactやCanvasは限定されたデータタイプにしか対応していませんが、MulmoChatの仕組みはサードパーティが新しいデータタイプやビューアーを自由に追加できます。

2. Communication-first（対話中心）

　ArtifactやCanvasは成果物の生成を目的としていますが、MulmoChatはLLMとユーザーのコミュニケーションを中心に設計されています。生成されるドキュメントやソフトウェアは、あくまでその対話の一部にすぎません。

この設計により、たとえば旅行代理店が顧客向け資料を作るだけでなく、LLMが“旅行代理店そのもの”としてユーザーに提案を行うことが可能になります。

さらに、この仕組みはLLMがユーザーから情報を得る場面にも使えます。下の例は、MulmoCast内で「病院のレセプション」として動作するロールです。LLMはユーザーから情報を得るためのフォームをダイナミックに生成し、自然な対話の流れで提示します。

![](https://mag2.thelifeisbeautiful.com/Nov2025/Receptionist.png)

このように、MulmoChatでは情報の生成と収集が、同じ自然言語インターフェイス上でシームレスに行われる。これこそが、AI-Nativeコンピューティング環境における新しい「ユーザー体験の完成形」です。

## Role of Domain-Specific Presentation Langauge

このアーキテクチャにおいて、とても重要な役割を果たすのは、ユーザーに情報（入力フォームを含む）を提示する際に、LLMが生成する、DSL（Domain-Specific Language）です。情報を表示するための言語なので、"Domain-Specific Presentation Langauge"と呼ぶべきかも知れません。

上に挙げた、スプレッドシート、ドキュメント、フォームのいずれにのケースでも、それぞれのToolが必要とするデータ形式は異なり、そのスキーマは、Toolの定義としてLLMに提示されています。LLMはユーザーからのリクエストに応じて、そのスキーマに則ったデータを生成し、Toolを呼び出します。

Toolはほとんどの場合、そのデータをそのままシステムにTool Specificなデータとして渡し、専用のビューアーがそのデータを画面に表示し、ユーザーとのやり取りをします。

ここでは、以下の二つの変換が行われるのです。

1. LLM: ユーザーの意図(intent)のDSLへの変換
2. 専用Viewer: DSLのGUIへの変換

つまりDSLと専用ビューアーは、テキストデータ（特にJSON）の生成が得意なLLMが、インタラクティブなGUIを表示することを可能にしているとも言えるのです。

DSLとしては、ドキュメントの作成の際に使っているMarkdownはを含め、HTML、SVG、TeXなどの汎用的でオープンなものを使うことも可能だし、Tool-specificな独自なものを使うことも可能です。

汎用的なものを利用した方が、それらを学習したLLMが性能を発揮しやすい面もありますが、汎用過ぎてトークン数が莫大になったり、想定したものを作ってもらえないケースも多々あるため、必要に応じて、DSLを使い分けるのが適切です。

LLMの開発者たちは、Tool Callとコードの生成能力を高めることに力を入れていますが、DSLの活用はその傾向との相性が良く、GPT−5や、Sonnet 4.5のような最先端の大規模モデルだけでなく、gpt-oss:20b、qwen3:30bのような小規模言語モデルであっても十分な性能が発揮されることがMulmoChatの開発を通して分かっています。

