# AI-Native Application Architecture

ChatGPTがOpenAIから発表されて3年が経とうとしています。その後、さまざまな生成系AIが作られ、function call、MCP、Code Interpretor、Artifact、Mulmi-modal LLM、Agentなどさまざまな仕組みが作られていますが、ChatGPTはいまだにテキストベースのチャットに留まっています。

私たちソフトウェア・エンジニアの間で、Claude Codeなどのチャット形式のプログラミング環境が幅広く使われていることは、LLMと人間の間の自然言語インターフェイス（Natural Language Interface）に大きな利点があることを証明しています。

MicrosoftのCoPilotは、Excelなどのグラフィカルなインターフェイスを持つアプリケーションにLLMの持つ自然言語インターフェイスを追加する試みですが、必ずしも幅広いユーザーに受け入れられてはいません。これは、ExcelがLLMが存在しない時代に設計されたアプリケーションであるから仕方がありません。

画像認識の機能を持ったLLMにブラウザーやアプリケーションを操作させるという試みも行われていますが、このアプローチにも同様の問題があります。

正しいアプローチは、Excelや他のアプリケーションの機能をAPIとしてLLMに提示し、LLMにユーザーの意図（intent）を一連のAPIコールに変換させるアプローチであることは明らかですが、そんな時代の「アプリケーション」とは何か、「OS」とは何か、そして、これまで存在していたユーザーとアプリケーションの間のグラフィカル・インターフェイスが、そこにどうフィットすべきなのかに関しては、まだ答えを見つけられていません。

この文章は、「AI-Nativeなコンピュータ（OS）のUser Experienceとアプリケーション・アーキテクチャ」という観点から、業界全体に「目指すべき方向」を示すために作られたMulmoChat(Multi-modal Chat)というオープンソースなプロトタイプを紹介するものです。
